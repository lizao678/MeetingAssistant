<template>
  <div class="realtime-view">
    <!-- å¤´éƒ¨æ§åˆ¶åŒº -->
    <el-card class="header-card" shadow="never">
      <div class="header-content">
        <div class="title-section">
          <h1 class="page-title">
            <el-icon class="title-icon"><Microphone /></el-icon>
            å®æ—¶è¯­éŸ³è¯†åˆ«
          </h1>
          <div class="status-indicator">
            <el-tag :type="statusTagType" :effect="isRecording ? 'dark' : 'plain'" size="small">
              <el-icon class="status-icon"><component :is="statusIcon" /></el-icon>
              {{ statusText }}
            </el-tag>
          </div>
        </div>
        
        <div class="controls-section">
          <el-space :size="16">
                         <!-- è¯­è¨€é€‰æ‹© -->
             <el-select v-model="selectedLang" placeholder="é€‰æ‹©è¯­è¨€" style="min-width: 120px">
               <el-option label="è‡ªåŠ¨æ£€æµ‹" value="auto" />
               <el-option label="ä¸­æ–‡" value="zh" />
               <el-option label="è‹±æ–‡" value="en" />
               <el-option label="æ—¥è¯­" value="ja" />
               <el-option label="éŸ©è¯­" value="ko" />
               <el-option label="ç²¤è¯­" value="yue" />
             </el-select>
            
            <!-- è¯´è¯äººè¯†åˆ«å¼€å…³ -->
            <el-switch
              v-model="speakerVerification"
              active-text="åŒºåˆ†å‘è¨€äºº"
              inactive-text="ä¸åŒºåˆ†"
              style="--el-switch-on-color: #13ce66"
            />
          </el-space>
        </div>
      </div>
      
      <!-- å½•éŸ³æ§åˆ¶æŒ‰é’® -->
      <div class="record-controls">
        <div class="control-buttons">
          <el-button
            :type="isRecording ? 'danger' : 'primary'"
            :size="'large'"
            :loading="isConnecting"
            :disabled="isTimeLimit"
            @click="toggleRecording"
            class="record-button"
          >
            <el-icon v-if="!isConnecting" size="20">
              <component :is="isRecording ? 'Stop' : 'VideoPlay'" />
            </el-icon>
            {{ isRecording ? 'åœæ­¢å½•éŸ³' : 'å¼€å§‹å½•éŸ³' }}
          </el-button>
          
          <!-- æš‚åœ/æ¢å¤æŒ‰é’® -->
          <el-button
            v-if="isRecording"
            :type="isPaused ? 'success' : 'warning'"
            size="large"
            @click="togglePause"
            class="pause-button"
          >
            <el-icon size="20">
              <component :is="isPaused ? 'VideoPlay' : 'VideoPause'" />
            </el-icon>
            {{ isPaused ? 'æ¢å¤å½•éŸ³' : 'æš‚åœå½•éŸ³' }}
          </el-button>
          
          <el-button
            v-if="messages.length > 0"
            @click="clearMessages"
            type="info"
            size="large"
            plain
          >
            <el-icon><Delete /></el-icon>
            æ¸…ç©ºè®°å½•
          </el-button>
        </div>
        
        <!-- å½•éŸ³æ—¶é•¿æ˜¾ç¤º -->
        <div v-if="isRecording || recordingDuration > 0" class="recording-time">
          <div class="time-display">
            <el-text 
              :type="isNearTimeLimit ? 'warning' : isTimeLimit ? 'danger' : 'primary'" 
              size="large"
              class="duration-text"
            >
              <el-icon><Timer /></el-icon>
              {{ formattedDuration }} / {{ formattedMaxDuration }}
            </el-text>
          </div>
          
          <!-- è¿›åº¦æ¡ -->
          <el-progress
            :percentage="recordingProgress"
            :status="isTimeLimit ? 'exception' : isNearTimeLimit ? 'warning' : 'success'"
            :show-text="false"
            :stroke-width="6"
            class="time-progress"
          />
          
          <!-- æ—¶é—´é™åˆ¶æç¤º -->
          <el-text v-if="isNearTimeLimit" type="warning" size="small">
            {{ isTimeLimit ? 'å·²è¾¾åˆ°æœ€å¤§å½•éŸ³æ—¶é•¿' : 'å³å°†è¾¾åˆ°æœ€å¤§å½•éŸ³æ—¶é•¿' }}
          </el-text>
        </div>
        
        <!-- éŸ³é¢‘è´¨é‡ç›‘æ§é¢æ¿ -->
        <div v-if="isRecording && !isPaused" class="audio-quality-panel">
          <div class="quality-header">
            <h4>ğŸ™ï¸ éŸ³é¢‘å¢å¼ºå®æ—¶ç›‘æ§</h4>
            <el-tag 
              :type="audioQuality.qualityLevel === 'excellent' ? 'success' : 
                     audioQuality.qualityLevel === 'good' ? 'primary' :
                     audioQuality.qualityLevel === 'fair' ? 'warning' : 'danger'"
              size="small"
            >
              {{ audioQuality.qualityLevel === 'excellent' ? 'ğŸŸ¢ ä¼˜ç§€' :
                 audioQuality.qualityLevel === 'good' ? 'ğŸ”µ è‰¯å¥½' :
                 audioQuality.qualityLevel === 'fair' ? 'ğŸŸ¡ ä¸€èˆ¬' : 'ğŸ”´ è¾ƒå·®' }}
            </el-tag>
          </div>
          
          <div class="quality-metrics">
            <div class="metric-item">
              <span class="metric-label">éŸ³é‡å¼ºåº¦:</span>
              <el-progress 
                :percentage="Math.min(audioQuality.rms * 500, 100)" 
                :show-text="false"
                :stroke-width="4"
                color="#67c23a"
              />
              <span class="metric-value">{{ (audioQuality.rms * 100).toFixed(1) }}%</span>
            </div>
            
            <div class="metric-item">
              <span class="metric-label">ä¿¡å™ªæ¯”:</span>
              <el-progress 
                :percentage="Math.max(0, Math.min((audioQuality.snr + 20) * 2, 100))" 
                :show-text="false"
                :stroke-width="4"
                :color="audioQuality.snr >= 20 ? '#67c23a' : audioQuality.snr >= 10 ? '#e6a23c' : '#f56c6c'"
              />
              <span class="metric-value">{{ audioQuality.snr.toFixed(1) }}dB</span>
            </div>
            
            <div class="metric-item">
              <span class="metric-label">åŠ¨æ€å¢ç›Š:</span>
              <el-progress 
                :percentage="Math.min(audioQuality.gain * 25, 100)" 
                :show-text="false"
                :stroke-width="4"
                color="#409eff"
              />
              <span class="metric-value">{{ audioQuality.gain.toFixed(1) }}x</span>
            </div>
          </div>
          
          <div class="enhancement-status">
            <div class="enhancement-items">
              <el-tag size="small" type="success">âœ“ å›å£°æ¶ˆé™¤</el-tag>
              <el-tag size="small" type="success">âœ“ å™ªå£°æŠ‘åˆ¶</el-tag>
              <el-tag size="small" type="success">âœ“ åŠ¨æ€å‹ç¼©</el-tag>
              <el-tag size="small" type="success">âœ“ è‡ªåŠ¨å¢ç›Š</el-tag>
              <el-tag size="small" type="success">âœ“ æ»¤æ³¢å¢å¼º</el-tag>
            </div>
          </div>
        </div>
      </div>
    </el-card>

    <!-- æ¶ˆæ¯æ˜¾ç¤ºåŒºåŸŸ -->
    <el-card class="messages-card" shadow="never">
      <template #header>
        <div class="messages-header">
          <span>è¯†åˆ«ç»“æœ</span>
          <el-text type="info" size="small">å®æ—¶æ˜¾ç¤ºè¯­éŸ³è¯†åˆ«å†…å®¹</el-text>
        </div>
      </template>
      
      <div ref="messagesContainer" class="messages-container">
        <div v-if="messages.length === 0" class="empty-state">
          <el-empty description="æš‚æ— è¯†åˆ«å†…å®¹">
            <template #image>
              <el-icon size="100" color="#c0c4cc"><Microphone /></el-icon>
            </template>
          </el-empty>
        </div>
        
        <div v-else class="messages-list">
          <div
            v-for="message in messages"
            :key="message.id"
            class="message-item"
            :class="`speaker-${message.speakerClass}`"
          >
            <div class="message-avatar">
              <el-avatar :size="36" :style="{ backgroundColor: message.speakerColor }">
                {{ message.speakerNumber }}
              </el-avatar>
            </div>
            
            <div class="message-content">
              <div class="message-header">
                <span class="speaker-name">{{ message.speakerId }}</span>
                <el-tag
                  v-if="message.confidence"
                  :type="getConfidenceType(message.confidence)"
                  size="small"
                  class="confidence-tag"
                >
                  ç½®ä¿¡åº¦: {{ (message.confidence * 100).toFixed(1) }}%
                </el-tag>
                <span class="message-time">{{ message.timestamp }}</span>
              </div>
              
              <div class="message-bubble">
                {{ message.text }}
              </div>
            </div>
          </div>
        </div>
      </div>
    </el-card>

    <!-- å‘è¨€äººæ•°é€‰æ‹©å¼¹çª— -->
    <SpeakerCountDialog
      v-model="showSpeakerDialog"
      :recording-data="currentRecordingData"
      @confirm="handleSpeakerDialogConfirm"
      @cancel="handleSpeakerDialogCancel"
    />
  </div>
</template>

<script setup lang="ts">
import { ref, computed, nextTick, onMounted, onUnmounted } from 'vue'
import { ElMessage, ElMessageBox, ElLoading } from 'element-plus'
import { useRouter } from 'vue-router'
import SpeakerCountDialog from '../components/SpeakerCountDialog.vue'
import recordingService from '@/services/recordingService'
import type { AudioMessage, RecordingStatus, SpeakerInfo } from '../types/audio'
import { useRecordingRouteGuard } from '@/composables/useRouteGuard'
import { useSettingsStore } from '@/stores/settingsStore'
import { storeToRefs } from 'pinia'

const router = useRouter()

// è·å–è®¾ç½®
const settingsStore = useSettingsStore()
const { speechSettings } = storeToRefs(settingsStore)

// å“åº”å¼æ•°æ®
const isRecording = ref(false)
const isConnecting = ref(false)
const isPaused = ref(false)
const selectedLang = ref('zh')
const speakerVerification = ref(true)
const messages = ref<AudioMessage[]>([])
const messagesContainer = ref<HTMLElement>()

// éŸ³é¢‘è´¨é‡ç›‘æ§
const audioQuality = ref({
  rms: 0,
  peak: 0,
  snr: 0,
  gain: 1.0,
  qualityLevel: 'excellent' as 'poor' | 'fair' | 'good' | 'excellent'
})
let qualityUpdateTimer: number | null = null

// å½•éŸ³æ—¶é•¿ç›¸å…³
const recordingDuration = ref(0) // å·²å½•åˆ¶æ—¶é•¿(ç§’)
const maxRecordingDuration = ref(3600) // æœ€å¤§å½•éŸ³æ—¶é•¿(ç§’) - 1å°æ—¶
let recordingTimer: number | null = null
let completeAudioBuffer: Float32Array[] = [] // æ–°å¢ï¼šä¿å­˜å®Œæ•´å½•éŸ³æ•°æ®

// WebSocketå’Œå½•éŸ³ç›¸å…³
let ws: WebSocket | null = null
let recorder: any = null
let audioContext: AudioContext | null = null
let timeInterval: number | null = null

// è¯´è¯äººç®¡ç†
const speakerColors = ['#409eff', '#67c23a', '#e6a23c', '#f56c6c', '#909399']
const speakerMap = new Map<string, SpeakerInfo>()
let speakerCounter = 0

// å‘è¨€äººæ•°é€‰æ‹©å¼¹çª—
const showSpeakerDialog = ref(false)
const currentRecordingData = ref({
  duration: 0,
  language: 'zh',
  audioBlob: undefined as Blob | undefined,
  messages: [] as AudioMessage[]
})

// è®¡ç®—å±æ€§
const statusText = computed(() => {
  if (isConnecting.value) return 'è¿æ¥ä¸­...'
  if (isRecording.value && isPaused.value) return 'å½•éŸ³æš‚åœ'
  if (isRecording.value) return 'å½•éŸ³ä¸­'
  return 'å‡†å¤‡å°±ç»ª'
})

const statusTagType = computed(() => {
  if (isConnecting.value) return 'warning'
  if (isRecording.value && isPaused.value) return 'info'
  if (isRecording.value) return 'danger'
  return 'success'
})

const statusIcon = computed(() => {
  if (isConnecting.value) return 'Loading'
  if (isRecording.value && isPaused.value) return 'VideoPause'
  if (isRecording.value) return 'VideoCamera'
  return 'SuccessFilled'
})

// æ—¶é—´æ ¼å¼åŒ–
const formatTime = (seconds: number) => {
  const hours = Math.floor(seconds / 3600)
  const minutes = Math.floor((seconds % 3600) / 60)
  const secs = seconds % 60
  
  if (hours > 0) {
    return `${hours.toString().padStart(2, '0')}:${minutes.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`
  }
  return `${minutes.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`
}

const formattedDuration = computed(() => formatTime(recordingDuration.value))
const formattedMaxDuration = computed(() => formatTime(maxRecordingDuration.value))

// å½•éŸ³è¿›åº¦ç™¾åˆ†æ¯”
const recordingProgress = computed(() => {
  return Math.min((recordingDuration.value / maxRecordingDuration.value) * 100, 100)
})

// æ˜¯å¦æ¥è¿‘æ—¶é—´é™åˆ¶
const isNearTimeLimit = computed(() => {
  return recordingDuration.value >= maxRecordingDuration.value * 0.9 // 90%
})

// æ˜¯å¦è¾¾åˆ°æ—¶é—´é™åˆ¶
const isTimeLimit = computed(() => {
  return recordingDuration.value >= maxRecordingDuration.value
})

// è·ç½®ä¿¡åº¦ç±»å‹
const getConfidenceType = (confidence: number) => {
  if (confidence > 0.8) return 'success'
  if (confidence > 0.6) return 'warning'
  return 'danger'
}

// è·å–è¯´è¯äººä¿¡æ¯
const getSpeakerInfo = (speakerId: string): SpeakerInfo => {
  if (!speakerMap.has(speakerId)) {
    const colorIndex = speakerCounter % speakerColors.length
    const speakerNumber = speakerCounter + 1
    
    speakerMap.set(speakerId, {
      id: speakerId,
      color: speakerColors[colorIndex],
      number: speakerNumber.toString(),
      className: `speaker-${speakerNumber}`
    })
    
    speakerCounter++
  }
  
  return speakerMap.get(speakerId)!
}

// æ·»åŠ æ¶ˆæ¯
const addMessage = (data: any) => {
  const speakerInfo = getSpeakerInfo(data.speaker_id || 'å‘è¨€äºº1')
  
  // æ­£ç¡®å¤„ç†æ¢è¡Œé€»è¾‘ï¼šå¦‚æœåç«¯æ˜ç¡®è¿”å›falseï¼Œå°±ä¸æ¢è¡Œï¼›å¦åˆ™é»˜è®¤æ¢è¡Œ
  const shouldNewLine = data.is_new_line !== undefined ? data.is_new_line : true
  
  const message: AudioMessage = {
    id: Date.now(),
    text: data.data || data.text || '',
    speakerId: data.speaker_id || 'å‘è¨€äºº1',
    speakerColor: speakerInfo.color,
    speakerNumber: speakerInfo.number,
    speakerClass: speakerInfo.className,
    timestamp: new Date().toLocaleTimeString('zh-CN', {
      hour12: false,
      hour: '2-digit',
      minute: '2-digit',
      second: '2-digit'
    }),
    confidence: data.confidence || 0,
    isNewLine: shouldNewLine,
    segmentType: data.segment_type || 'continue'
  }
  
  // æ™ºèƒ½æ¢è¡Œé€»è¾‘ï¼š
  // 1. å¦‚æœéœ€è¦æ¢è¡Œ (shouldNewLine = true)ï¼Œæ€»æ˜¯åˆ›å»ºæ–°æ¶ˆæ¯
  // 2. å¦‚æœä¸éœ€è¦æ¢è¡Œ (shouldNewLine = false)ï¼Œä¸”æ˜¯åŒä¸€è¯´è¯äººï¼Œåˆ™è¿½åŠ åˆ°æœ€åä¸€æ¡æ¶ˆæ¯
  const lastMessage = messages.value[messages.value.length - 1]
  
  if (!shouldNewLine && 
      lastMessage && 
      lastMessage.speakerId === message.speakerId &&
      lastMessage.text.trim() !== '') {
    // è¿½åŠ åˆ°ç°æœ‰æ¶ˆæ¯ï¼Œç”¨ç©ºæ ¼åˆ†éš”
    lastMessage.text += (lastMessage.text.endsWith(' ') ? '' : ' ') + message.text
    lastMessage.timestamp = message.timestamp
    lastMessage.confidence = message.confidence
    console.log(`è¿½åŠ æ¶ˆæ¯: ${message.text} (è¯´è¯äºº: ${message.speakerId})`)
  } else {
    // åˆ›å»ºæ–°æ¶ˆæ¯
    messages.value.push(message)
    console.log(`æ–°æ¶ˆæ¯: ${message.text} (è¯´è¯äºº: ${message.speakerId}, æ¢è¡Œ: ${shouldNewLine})`)
  }
  
  // è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
  nextTick(() => {
    if (messagesContainer.value) {
      messagesContainer.value.scrollTop = messagesContainer.value.scrollHeight
    }
  })
}

// éŸ³é¢‘å¢å¼ºå™¨æ¥å£
interface AudioEnhancer {
  noiseFloor: number
  silenceThreshold: number
  rmsHistory: number[]
  maxRmsHistory: number
  currentGain: number
  targetGain: number
  gainSmoothingFactor: number
  targetRMS: number
  maxGain: number
  enableAutoGain: boolean
  enableNoiseSuppression: boolean
  analyzeAudio(buffer: Float32Array): { rms: number; peak: number; snr: number }
  denoiseBuffer(buffer: Float32Array): Float32Array
  normalizeAudio(buffer: Float32Array): Float32Array
}

// å¢å¼ºå‚æ•°æ¥å£
interface EnhancementParams {
  compressorRatio: number
  gain: number
  targetRMS: number
  maxGain: number
}

// åˆ›å»ºéŸ³é¢‘å¤„ç†å™¨
const createAudioProcessor = (stream: MediaStream) => {
  const sampleBits = 16
  const inputSampleRate = 48000
  const outputSampleRate = 16000
  const channelCount = 1
  
  const context = new AudioContext()
  const audioInput = context.createMediaStreamSource(stream)
  
  // åˆ›å»ºåŸºç¡€å¤„ç†èŠ‚ç‚¹
  const scriptProcessor = context.createScriptProcessor(4096, channelCount, channelCount)
  
  // åªæ·»åŠ æœ€åŸºç¡€çš„å¤„ç†
  // 1. é«˜é€šæ»¤æ³¢å™¨ - å»é™¤ä½é¢‘å™ªå£°
  const highpassFilter = context.createBiquadFilter()
  highpassFilter.type = 'highpass'
  highpassFilter.frequency.setValueAtTime(80, context.currentTime)
  
  // 2. è½»å¾®å‹ç¼© - åªä¸ºäº†æ§åˆ¶è¿‡å¤§çš„éŸ³é‡æ³¢åŠ¨
  const compressor = context.createDynamicsCompressor()
  compressor.threshold.setValueAtTime(-24, context.currentTime)
  compressor.knee.setValueAtTime(30, context.currentTime)
  compressor.ratio.setValueAtTime(2, context.currentTime)  // æœ€è½»å¾®çš„å‹ç¼©æ¯”
  compressor.attack.setValueAtTime(0.05, context.currentTime)
  compressor.release.setValueAtTime(0.25, context.currentTime)
  
  // è¿æ¥å¤„ç†é“¾
  audioInput
    .connect(highpassFilter)
    .connect(compressor)
    .connect(scriptProcessor)
  scriptProcessor.connect(context.destination)
  
  const audioData = {
    size: 0,
    buffer: [] as Float32Array[],
    clear() {
      this.buffer = []
      this.size = 0
    },
    input(data: Float32Array) {
      this.buffer.push(new Float32Array(data))
      this.size += data.length
      completeAudioBuffer.push(new Float32Array(data))
    },
    encodePCM() {
      const bytes = new Float32Array(this.size)
      let offset = 0
      for (let i = 0; i < this.buffer.length; i++) {
        bytes.set(this.buffer[i], offset)
        offset += this.buffer[i].length
      }
      
      const dataLength = bytes.length * (sampleBits / 8)
      const buffer = new ArrayBuffer(dataLength)
      const data = new DataView(buffer)
      offset = 0
      
      for (let i = 0; i < bytes.length; i++, offset += 2) {
        const s = Math.max(-1, Math.min(1, bytes[i]))
        data.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true)
      }
      
      return new Blob([data], { type: 'audio/pcm' })
    }
  }
  
  // é™é‡‡æ ·å‡½æ•°
  const downsampleBuffer = (buffer: Float32Array, inputSampleRate: number, outputSampleRate: number) => {
    if (outputSampleRate === inputSampleRate) {
      return buffer
    }
    const sampleRateRatio = inputSampleRate / outputSampleRate
    const newLength = Math.round(buffer.length / sampleRateRatio)
    const result = new Float32Array(newLength)
    let offsetResult = 0
    let offsetBuffer = 0
    
    while (offsetResult < result.length) {
      const nextOffsetBuffer = Math.round((offsetResult + 1) * sampleRateRatio)
      let accum = 0
      let count = 0
      for (let i = offsetBuffer; i < nextOffsetBuffer && i < buffer.length; i++) {
        accum += buffer[i]
        count++
      }
      result[offsetResult] = accum / count
      offsetResult++
      offsetBuffer = nextOffsetBuffer
    }
    return result
  }
  
  scriptProcessor.onaudioprocess = (e) => {
    const resampledData = downsampleBuffer(
      e.inputBuffer.getChannelData(0),
      inputSampleRate,
      outputSampleRate
    )
    audioData.input(resampledData)
  }
  
  // è¿æ¥åˆ°è¾“å‡º
  scriptProcessor.connect(context.destination)
  
  return {
    start() {},
    stop() {
      scriptProcessor.disconnect()
      audioInput.disconnect()
    },
    getQualityStats() {
      return {
        averageRMS: 0,
        peakLevel: 0,
        snr: 0,
        processingGain: 1.0
      }
    },
    getBlob() {
      return audioData.encodePCM()
    },
    clear() {
      audioData.clear()
    },
    getCompleteAudioWAV() {
      return createWAVBlob(completeAudioBuffer, outputSampleRate)
    }
  }
}

// æ–°å¢ï¼šåˆ›å»ºWAVæ ¼å¼éŸ³é¢‘æ–‡ä»¶
const createWAVBlob = (audioBuffers: Float32Array[], sampleRate: number) => {
  // è®¡ç®—æ€»é•¿åº¦
  let totalLength = 0
  for (const buffer of audioBuffers) {
    totalLength += buffer.length
  }
  
  // åˆå¹¶æ‰€æœ‰éŸ³é¢‘æ•°æ®
  const mergedBuffer = new Float32Array(totalLength)
  let offset = 0
  for (const buffer of audioBuffers) {
    mergedBuffer.set(buffer, offset)
    offset += buffer.length
  }
  
  // è½¬æ¢ä¸º16ä½PCM
  const pcmData = new Int16Array(mergedBuffer.length)
  for (let i = 0; i < mergedBuffer.length; i++) {
    const s = Math.max(-1, Math.min(1, mergedBuffer[i]))
    pcmData[i] = s < 0 ? s * 0x8000 : s * 0x7FFF
  }
  
  // åˆ›å»ºWAVæ–‡ä»¶å¤´
  const channels = 1
  const bitsPerSample = 16
  const byteRate = sampleRate * channels * bitsPerSample / 8
  const blockAlign = channels * bitsPerSample / 8
  const dataSize = pcmData.length * 2
  const fileSize = 44 + dataSize
  
  const arrayBuffer = new ArrayBuffer(fileSize)
  const view = new DataView(arrayBuffer)
  
  // WAVæ–‡ä»¶å¤´
  const writeString = (offset: number, string: string) => {
    for (let i = 0; i < string.length; i++) {
      view.setUint8(offset + i, string.charCodeAt(i))
    }
  }
  
  writeString(0, 'RIFF')
  view.setUint32(4, fileSize - 8, true)
  writeString(8, 'WAVE')
  writeString(12, 'fmt ')
  view.setUint32(16, 16, true) // fmt chunk size
  view.setUint16(20, 1, true) // audio format (PCM)
  view.setUint16(22, channels, true)
  view.setUint32(24, sampleRate, true)
  view.setUint32(28, byteRate, true)
  view.setUint16(32, blockAlign, true)
  view.setUint16(34, bitsPerSample, true)
  writeString(36, 'data')
  view.setUint32(40, dataSize, true)
  
  // å†™å…¥PCMæ•°æ®
  let dataOffset = 44
  for (let i = 0; i < pcmData.length; i++) {
    view.setInt16(dataOffset, pcmData[i], true)
    dataOffset += 2
  }
  
  return new Blob([arrayBuffer], { type: 'audio/wav' })
}

// åˆ‡æ¢å½•éŸ³çŠ¶æ€
const toggleRecording = async () => {
  if (isRecording.value) {
    await stopRecording()
  } else {
    await startRecording()
  }
}

// åˆ‡æ¢æš‚åœçŠ¶æ€
const togglePause = () => {
  if (isPaused.value) {
    // æ¢å¤å½•éŸ³
    resumeRecording()
  } else {
    // æš‚åœå½•éŸ³
    pauseRecording()
  }
}

// æš‚åœå½•éŸ³
const pauseRecording = () => {
  if (!isRecording.value) return
  
  isPaused.value = true
  
  // åœæ­¢å®šæ—¶å™¨
  if (timeInterval) {
    clearInterval(timeInterval)
    timeInterval = null
  }
  
  // åœæ­¢å½•éŸ³è®¡æ—¶å™¨
  if (recordingTimer) {
    clearInterval(recordingTimer)
    recordingTimer = null
  }
  
  ElMessage.info('å½•éŸ³å·²æš‚åœ')
}

// æ¢å¤å½•éŸ³
const resumeRecording = () => {
  if (!isRecording.value || !isPaused.value) return
  
  isPaused.value = false
  
  // é‡æ–°å¼€å§‹éŸ³é¢‘æ•°æ®å‘é€
  timeInterval = setInterval(() => {
    if (ws && ws.readyState === WebSocket.OPEN && !isPaused.value) {
      const audioBlob = recorder.getBlob()
      if (audioBlob.size > 0) {
        console.log('å‘é€éŸ³é¢‘æ•°æ®ï¼Œå¤§å°:', audioBlob.size)
        ws.send(audioBlob)
        recorder.clear()
      }
    }
  }, 500)
  
  // é‡æ–°å¼€å§‹å½•éŸ³è®¡æ—¶å™¨
  startRecordingTimer()
  
  ElMessage.success('å½•éŸ³å·²æ¢å¤')
}

// å¼€å§‹å½•éŸ³è®¡æ—¶å™¨
const startRecordingTimer = () => {
  recordingTimer = setInterval(() => {
    if (!isPaused.value) {
      recordingDuration.value++
      
      // æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§æ—¶é•¿
      if (recordingDuration.value >= maxRecordingDuration.value) {
        ElMessage.warning('å·²è¾¾åˆ°æœ€å¤§å½•éŸ³æ—¶é•¿ï¼Œè‡ªåŠ¨åœæ­¢å½•éŸ³')
        stopRecording()
      }
    }
  }, 1000)
}

// åœæ­¢å½•éŸ³è®¡æ—¶å™¨
const stopRecordingTimer = () => {
  if (recordingTimer) {
    clearInterval(recordingTimer)
    recordingTimer = null
  }
}

// å¼€å§‹éŸ³é¢‘è´¨é‡ç›‘æ§
const startQualityMonitoring = () => {
  if (qualityUpdateTimer) {
    clearInterval(qualityUpdateTimer)
  }
  
  qualityUpdateTimer = setInterval(() => {
    if (recorder && isRecording.value && !isPaused.value) {
      try {
        const stats = recorder.getQualityStats()
        audioQuality.value.rms = Math.round(stats.averageRMS * 100) / 100
        audioQuality.value.peak = Math.round(stats.peakLevel * 100) / 100
        audioQuality.value.snr = Math.round(stats.snr * 10) / 10
        audioQuality.value.gain = Math.round(stats.processingGain * 100) / 100
        
        // æ ¹æ®ä¿¡å™ªæ¯”åˆ¤æ–­è´¨é‡ç­‰çº§
        if (stats.snr >= 20) {
          audioQuality.value.qualityLevel = 'excellent'
        } else if (stats.snr >= 10) {
          audioQuality.value.qualityLevel = 'good'
        } else if (stats.snr >= 0) {
          audioQuality.value.qualityLevel = 'fair'
        } else {
          audioQuality.value.qualityLevel = 'poor'
        }
      } catch (error) {
        console.log('éŸ³é¢‘è´¨é‡ç›‘æ§æ›´æ–°å¤±è´¥:', error)
      }
    }
  }, 200) // æ¯200msæ›´æ–°ä¸€æ¬¡
}

// åœæ­¢éŸ³é¢‘è´¨é‡ç›‘æ§
const stopQualityMonitoring = () => {
  if (qualityUpdateTimer) {
    clearInterval(qualityUpdateTimer)
    qualityUpdateTimer = null
  }
  
  // é‡ç½®è´¨é‡æ•°æ®
  audioQuality.value = {
    rms: 0,
    peak: 0,
    snr: 0,
    gain: 1.0,
    qualityLevel: 'excellent'
  }
}

// å¼€å§‹å½•éŸ³
const startRecording = async () => {
  try {
    isConnecting.value = true
    
    // æ¸…ç©ºä¹‹å‰çš„éŸ³é¢‘æ•°æ®
    completeAudioBuffer = []
    
    // è·å–éŸ³é¢‘æµ - æ·»åŠ å®Œæ•´çš„éŸ³é¢‘å¢å¼ºå‚æ•°
    const audioConstraints: any = {
      // åŸºç¡€å¢å¼ºåŠŸèƒ½
      echoCancellation: true,          // å›å£°æ¶ˆé™¤
      noiseSuppression: true,          // å™ªå£°æŠ‘åˆ¶
      autoGainControl: true,           // è‡ªåŠ¨å¢ç›Šæ§åˆ¶
      
      // é«˜çº§éŸ³é¢‘å‚æ•°
      sampleRate: 48000,               // é«˜é‡‡æ ·ç‡è·å–æ›´å¤šç»†èŠ‚
      sampleSize: 16,                  // 16ä½é‡‡æ ·æ·±åº¦
      channelCount: 1,                 // å•å£°é“
      
      // åŠ¨æ€å¢å¼ºå‚æ•°ï¼ˆChromeç‰¹æœ‰ï¼‰
      googEchoCancellation: true,      // Googleå›å£°æ¶ˆé™¤
      googAutoGainControl: true,       // Googleè‡ªåŠ¨å¢ç›Š
      googNoiseSuppression: true,      // Googleå™ªå£°æŠ‘åˆ¶
      googHighpassFilter: true,        // é«˜é€šæ»¤æ³¢å™¨
      googTypingNoiseDetection: true,  // é”®ç›˜å™ªéŸ³æ£€æµ‹
      googBeamforming: true,           // æ³¢æŸæˆå½¢
      googArrayGeometry: true,         // é˜µåˆ—å‡ ä½•
      googAudioMirroring: false,       // ç¦ç”¨éŸ³é¢‘é•œåƒ
      
      // å»¶è¿Ÿå’Œå¤„ç†ä¼˜åŒ–
      latency: 0.02,                   // ä½å»¶è¿Ÿï¼ˆ20msï¼‰
      volume: 1.0                      // æ ‡å‡†éŸ³é‡
    }
    
    const stream = await navigator.mediaDevices.getUserMedia({
      audio: audioConstraints
    })
    
    // å»ºç«‹WebSocketè¿æ¥
    const wsUrl = getWebSocketUrl()
    const queryParams = new URLSearchParams({
      lang: selectedLang.value,
      sv: speakerVerification.value ? '1' : '0'
    })
    
    ws = new WebSocket(`${wsUrl}/ws/transcribe?${queryParams}`)
    ws.binaryType = 'arraybuffer'
    
    ws.onopen = () => {
      console.log('WebSocketè¿æ¥å·²å»ºç«‹')
      isConnecting.value = false
      isRecording.value = true
      
      // åˆ›å»ºPCMå½•éŸ³å™¨
      recorder = createAudioProcessor(stream)
      recorder.start()
      
      // å®šæ—¶å‘é€éŸ³é¢‘æ•°æ®
      timeInterval = setInterval(() => {
        if (ws && ws.readyState === WebSocket.OPEN && !isPaused.value) {
          const audioBlob = recorder.getBlob()
          if (audioBlob.size > 0) {
            console.log('å‘é€éŸ³é¢‘æ•°æ®ï¼Œå¤§å°:', audioBlob.size)
            ws.send(audioBlob)
            recorder.clear()
          }
        }
      }, 500)
      
      // å¼€å§‹å½•éŸ³è®¡æ—¶å™¨
      startRecordingTimer()
      
      // å¼€å§‹éŸ³é¢‘è´¨é‡ç›‘æ§
      startQualityMonitoring()
      
      ElMessage.success('ğŸ™ï¸ å¼€å§‹å½•éŸ³ - éŸ³é¢‘å¢å¼ºå·²å¯ç”¨')
    }
    
    ws.onmessage = (event) => {
      try {
        const data = JSON.parse(event.data)
        if (data.code === 0 && data.data) {
          addMessage(data)
        }
      } catch (error) {
        console.error('è§£ææ¶ˆæ¯å¤±è´¥:', error)
      }
    }
    
    ws.onerror = (error) => {
      console.error('WebSocketè¿æ¥é”™è¯¯:', error)
      isConnecting.value = false
      ElMessage.error('è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè®¾ç½®')
    }
    
    ws.onclose = () => {
      console.log('WebSocketè¿æ¥å·²å…³é—­')
      isConnecting.value = false
    }
    
  } catch (error: any) {
    console.error('å¯åŠ¨å½•éŸ³å¤±è´¥:', error)
    isConnecting.value = false
    ElMessage.error(`å½•éŸ³å¯åŠ¨å¤±è´¥: ${error.message}`)
  }
}

// åœæ­¢å½•éŸ³
const stopRecording = async (showMessage = true) => {
  isRecording.value = false
  isConnecting.value = false
  isPaused.value = false
  
  // åœæ­¢æ‰€æœ‰å®šæ—¶å™¨
  if (timeInterval) {
    clearInterval(timeInterval)
    timeInterval = null
  }
  
  stopRecordingTimer()
  
  // åœæ­¢éŸ³é¢‘è´¨é‡ç›‘æ§
  stopQualityMonitoring()
  
  // ä¿å­˜æœ€ç»ˆçš„å®Œæ•´éŸ³é¢‘æ•°æ®ï¼ˆåœ¨é”€æ¯recorderä¹‹å‰ï¼‰
  let finalAudioBlob: Blob | undefined = undefined
  if (recorder && completeAudioBuffer.length > 0) {
    finalAudioBlob = recorder.getCompleteAudioWAV()
    if (finalAudioBlob) {
      console.log('ä¿å­˜æœ€ç»ˆéŸ³é¢‘æ•°æ®ï¼Œå¤§å°:', finalAudioBlob.size)
    }
  }
  
  // åœæ­¢å½•éŸ³å™¨
  if (recorder) {
    recorder.stop()
    recorder = null
  }
  
  // å…³é—­WebSocketè¿æ¥
  if (ws) {
    ws.close()
    ws = null
  }
  
  // å¦‚æœæœ‰å½•éŸ³å†…å®¹ä¸”éœ€è¦æ˜¾ç¤ºæ¶ˆæ¯ï¼Œåˆ™æ˜¾ç¤ºå‘è¨€äººé€‰æ‹©å¼¹çª—
  if (showMessage && messages.value.length > 0 && recordingDuration.value > 3 && finalAudioBlob) {
    // å‡†å¤‡å½•éŸ³æ•°æ®
    currentRecordingData.value = {
      duration: recordingDuration.value,
      language: selectedLang.value,
      audioBlob: finalAudioBlob, // ä½¿ç”¨ä¿å­˜çš„éŸ³é¢‘æ•°æ®
      messages: [...messages.value]
    }
    
    // æ˜¾ç¤ºå‘è¨€äººé€‰æ‹©å¼¹çª—
    showSpeakerDialog.value = true
  } else if (showMessage) {
    ElMessage.info(`å½•éŸ³å·²åœæ­¢ï¼Œæ€»æ—¶é•¿: ${formattedDuration.value}`)
    
    // å¦‚æœæ²¡æœ‰æ˜¾ç¤ºå¼¹çª—ï¼Œæ¸…ç©ºéŸ³é¢‘ç¼“å†²åŒº
    completeAudioBuffer = []
  }
}

// æ¸…ç©ºæ¶ˆæ¯
const clearMessages = async () => {
  try {
    await ElMessageBox.confirm('ç¡®å®šè¦æ¸…ç©ºæ‰€æœ‰è¯†åˆ«è®°å½•å—ï¼Ÿ', 'ç¡®è®¤æ¸…ç©º', {
      type: 'warning',
      confirmButtonText: 'ç¡®å®š',
      cancelButtonText: 'å–æ¶ˆ'
    })
    
    messages.value = []
    speakerMap.clear()
    speakerCounter = 0
    
    // é‡ç½®å½•éŸ³æ—¶é•¿ï¼ˆåªæœ‰åœ¨æ²¡æœ‰å½•éŸ³æ—¶æ‰é‡ç½®ï¼‰
    if (!isRecording.value) {
      recordingDuration.value = 0
    }
    
    ElMessage.success('è®°å½•å·²æ¸…ç©º')
  } catch {
    // ç”¨æˆ·å–æ¶ˆæ“ä½œ
  }
}

// è·å–WebSocket URLï¼ˆæ ¹æ®ç¯å¢ƒè‡ªåŠ¨æ£€æµ‹ï¼‰
const getWebSocketUrl = () => {
  const hostname = window.location.hostname
  const protocol = window.location.protocol
  
  // æœåŠ¡å™¨ç¯å¢ƒé…ç½®
  if (hostname === '192.168.100.205' || hostname.includes('192.168.') || protocol === 'https:') {
    return 'wss://192.168.100.205:8989'
  }
  
  // æœ¬åœ°ç¯å¢ƒé…ç½®
  return 'ws://127.0.0.1:26000'
}

// å¤„ç†å‘è¨€äººé€‰æ‹©å¼¹çª—ç¡®è®¤
const handleSpeakerDialogConfirm = async (data: any) => {
  try {
    const loading = ElLoading.service({
      lock: true,
      text: 'AIæ­£åœ¨å¤„ç†å½•éŸ³æ•°æ®...',
      background: 'rgba(0, 0, 0, 0.7)'
    })
    
    // æ£€æŸ¥æ˜¯å¦æœ‰å½•éŸ³æ•°æ®
    if (!currentRecordingData.value?.audioBlob) {
      loading.close()
      ElMessage.error('æ²¡æœ‰å½•éŸ³æ•°æ®å¯ä»¥ä¿å­˜')
      return
    }
    
    // ä½¿ç”¨ä¿å­˜çš„éŸ³é¢‘æ•°æ®
    const audioBlob = currentRecordingData.value.audioBlob
    console.log('ä½¿ç”¨ä¿å­˜çš„WAVéŸ³é¢‘æ–‡ä»¶ï¼Œå¤§å°:', audioBlob.size)
    
    // åˆ›å»ºçœŸå®çš„éŸ³é¢‘æ–‡ä»¶
    const audioFile = new File([audioBlob], `recording_${Date.now()}.wav`, { 
      type: 'audio/wav',
      lastModified: Date.now() 
    })
    
    // è°ƒç”¨åç«¯APIæäº¤å½•éŸ³æ•°æ®
    const requestData = {
      audioFile: audioFile,
      speakerCount: data.speakerCount,
      language: data.language || selectedLang.value,
      smartPunctuation: data.smartPunctuation !== false,
      numberConversion: data.numberConversion !== false,
      generateSummary: data.generateSummary !== false,
      summaryType: data.summaryType || 'meeting'
    }
    
    console.log('æ­£åœ¨æäº¤å½•éŸ³å¤„ç†è¯·æ±‚:', requestData)
    
    const response = await recordingService.processRecording(requestData)
    
    loading.close()
    
    console.log('APIå“åº”:', response)
    
    if (response.success && response.recording_id) {
      ElMessage.success('å½•éŸ³å·²æäº¤AIå¤„ç†ï¼Œæ­£åœ¨è·³è½¬åˆ°è¯¦æƒ…é¡µ...')
      
      // æ¸…ç©ºå½“å‰å½•éŸ³æ•°æ®
      messages.value = []
      speakerMap.clear()
      speakerCounter = 0
      recordingDuration.value = 0
      completeAudioBuffer = []
      currentRecordingData.value = {
        duration: 0,
        language: 'zh',
        audioBlob: undefined,
        messages: []
      }
      
      // è·³è½¬åˆ°å½•éŸ³è¯¦æƒ…é¡µ
      setTimeout(() => {
        router.push(`/recording/${response.recording_id}`)
      }, 1000)
    } else {
      throw new Error(response.error || response.message || 'å¤„ç†å¤±è´¥')
    }
    
  } catch (error: any) {
    ElMessage.error(`ä¿å­˜å½•éŸ³è®°å½•å¤±è´¥: ${error.message || error}`)
    console.error('ä¿å­˜å½•éŸ³å¤±è´¥:', error)
  }
}

// å¤„ç†å‘è¨€äººé€‰æ‹©å¼¹çª—å–æ¶ˆ
const handleSpeakerDialogCancel = () => {
  ElMessage.info('å·²å–æ¶ˆä¿å­˜å½•éŸ³')
}

// ä½¿ç”¨ç»Ÿä¸€çš„è·¯ç”±æ‹¦æˆªç®¡ç†
useRecordingRouteGuard(
  () => isRecording.value, // æ‹¦æˆªæ¡ä»¶ï¼šæ­£åœ¨å½•éŸ³æ—¶
  async () => {
    // ç¡®è®¤é€€å‡ºæ—¶çš„å›è°ƒï¼šåœæ­¢å½•éŸ³ï¼ˆä¸æ˜¾ç¤ºæç¤ºï¼‰
    if (isRecording.value) {
      await stopRecording(false)
    }
  }
)

// é¡µé¢å¯è§æ€§å˜åŒ–å¤„ç†
const handleVisibilityChange = () => {
  if (document.hidden && isRecording.value) {
    console.log('é¡µé¢éšè—ï¼Œå½•éŸ³ä»åœ¨è¿›è¡Œä¸­')
  }
}

// ç»„ä»¶æŒ‚è½½æ—¶æ·»åŠ äº‹ä»¶ç›‘å¬
onMounted(() => {
  console.log('å®æ—¶è¯­éŸ³è¯†åˆ«é¡µé¢å·²åŠ è½½')
  document.addEventListener('visibilitychange', handleVisibilityChange)
})

// ç»„ä»¶å¸è½½æ—¶ç§»é™¤äº‹ä»¶ç›‘å¬
onUnmounted(() => {
  console.log('å®æ—¶è¯­éŸ³è¯†åˆ«é¡µé¢å·²å¸è½½')
  document.removeEventListener('visibilitychange', handleVisibilityChange)
  
  // æ¸…ç†å½•éŸ³ç›¸å…³èµ„æº
  if (isRecording.value) {
    stopRecording(false)
  }
})
</script>

<style scoped>
.realtime-view {
  display: flex;
  flex-direction: column;
  gap: 20px;
  padding: 20px;
  min-height: calc(100vh - 60px);
}

.header-card {
  border-radius: 16px;
  border: none;
}

.header-content {
  display: flex;
  justify-content: space-between;
  align-items: flex-start;
  margin-bottom: 24px;
  gap: 20px;
  flex-wrap: wrap;
}

.title-section {
  display: flex;
  align-items: center;
  gap: 16px;
}

.page-title {
  margin: 0;
  display: flex;
  align-items: center;
  gap: 8px;
  font-size: 24px;
  font-weight: 600;
  color: #303133;
}

.title-icon {
  color: #409eff;
}

.status-indicator .status-icon {
  margin-right: 4px;
}

.controls-section {
  display: flex;
  align-items: center;
  flex-wrap: wrap;
  gap: 16px;
  flex: 1;
  justify-content: flex-end;
}

.record-controls {
  display: flex;
  flex-direction: column;
  align-items: center;
  gap: 20px;
  margin-top: 4px;
}

.control-buttons {
  display: flex;
  justify-content: center;
  align-items: center;
  gap: 20px;
  flex-wrap: wrap;
}

.recording-time {
  display: flex;
  flex-direction: column;
  align-items: center;
  gap: 12px;
  padding: 16px 24px;
  background: var(--el-bg-color-page);
  border-radius: 12px;
  border: 1px solid var(--el-border-color-light);
  min-width: 320px;
  max-width: 420px;
  box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
}

.time-display {
  display: flex;
  align-items: center;
  gap: 8px;
}

.duration-text {
  font-weight: 600;
  font-family: 'SF Mono', 'Monaco', 'Menlo', 'Courier New', monospace;
  font-size: 16px;
}

.time-progress {
  width: 100%;
}

.pause-button {
  font-weight: 600;
}

/* éŸ³é¢‘è´¨é‡ç›‘æ§é¢æ¿æ ·å¼ */
.audio-quality-panel {
  margin-top: 20px;
  padding: 16px 20px;
  background: linear-gradient(135deg, #f8fffe 0%, #f0f9ff 100%);
  border-radius: 12px;
  border: 1px solid #e1f5fe;
  box-shadow: 0 2px 8px rgba(0, 100, 200, 0.1);
  max-width: 600px;
  margin-left: auto;
  margin-right: auto;
}

.quality-header {
  display: flex;
  align-items: center;
  justify-content: space-between;
  margin-bottom: 16px;
}

.quality-header h4 {
  margin: 0;
  font-size: 16px;
  font-weight: 600;
  color: #2c3e50;
  display: flex;
  align-items: center;
  gap: 8px;
}

.quality-metrics {
  display: flex;
  flex-direction: column;
  gap: 12px;
  margin-bottom: 16px;
}

.metric-item {
  display: flex;
  align-items: center;
  gap: 12px;
  padding: 8px 0;
}

.metric-label {
  font-size: 14px;
  font-weight: 500;
  color: #606266;
  min-width: 80px;
  flex-shrink: 0;
}

.metric-item .el-progress {
  flex: 1;
  max-width: 200px;
}

.metric-value {
  font-size: 13px;
  font-weight: 600;
  color: #409eff;
  font-family: 'SF Mono', 'Monaco', 'Menlo', 'Courier New', monospace;
  min-width: 50px;
  text-align: right;
}

.enhancement-status {
  border-top: 1px solid #e1f5fe;
  padding-top: 12px;
}

.enhancement-items {
  display: flex;
  flex-wrap: wrap;
  gap: 6px;
  justify-content: center;
}

.enhancement-items .el-tag {
  font-size: 12px;
  padding: 2px 8px;
  border-radius: 12px;
}

/* å“åº”å¼è®¾è®¡ */
@media (max-width: 768px) {
  .audio-quality-panel {
    margin: 16px -4px 0;
    border-radius: 8px;
  }
  
  .quality-metrics {
    gap: 8px;
  }
  
  .metric-item {
    flex-direction: column;
    align-items: flex-start;
    gap: 6px;
    padding: 6px 0;
  }
  
  .metric-item .el-progress {
    width: 100%;
    max-width: none;
  }
  
  .enhancement-items {
    justify-content: flex-start;
  }
}

.record-button {
  padding: 12px 32px;
  font-size: 16px;
  font-weight: 600;
  border-radius: 8px;
  transition: all 0.3s;
}

.messages-card {
  flex: 1;
  border-radius: 16px;
  overflow: hidden;
  border: none;
  box-shadow: 0 4px 12px rgba(0, 0, 0, 0.05);
}

.messages-header {
  display: flex;
  align-items: center;
  justify-content: space-between;
}

.messages-container {
  height: 60vh;
  min-height: 400px;
  max-height: calc(100vh - 300px);
  overflow-y: auto;
  padding: 20px 0;
}

.empty-state {
  height: 100%;
  display: flex;
  align-items: center;
  justify-content: center;
}

.messages-list {
  display: flex;
  flex-direction: column;
  gap: 20px;
  padding: 0 8px;
}

.message-item {
  display: flex;
  gap: 12px;
  animation: fadeInUp 0.3s ease-out;
}

@keyframes fadeInUp {
  from {
    opacity: 0;
    transform: translateY(20px);
  }
  to {
    opacity: 1;
    transform: translateY(0);
  }
}

.message-content {
  flex: 1;
  max-width: min(calc(100% - 60px), 800px);
}

.message-header {
  display: flex;
  align-items: center;
  gap: 8px;
  margin-bottom: 6px;
}

.speaker-name {
  font-weight: 600;
  color: #303133;
  font-size: 14px;
}

.confidence-tag {
  font-size: 12px;
}

.message-time {
  font-size: 12px;
  color: #909399;
  margin-left: auto;
}

.message-bubble {
  background: #f8f9fa;
  padding: 14px 18px;
  border-radius: 16px;
  box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
  line-height: 1.6;
  color: #303133;
  word-wrap: break-word;
  position: relative;
  border: 1px solid rgba(0, 0, 0, 0.04);
  transition: all 0.2s ease;
}

.message-bubble::before {
  content: '';
  position: absolute;
  top: 10px;
  left: -7px;
  width: 0;
  height: 0;
  border-top: 7px solid transparent;
  border-bottom: 7px solid transparent;
  border-right: 7px solid #f8f9fa;
  filter: drop-shadow(-1px 0 1px rgba(0, 0, 0, 0.03));
}

/* å“åº”å¼è®¾è®¡ */
@media (max-width: 768px) {
  .realtime-view {
    padding: 12px;
    gap: 16px;
  }
  
  .header-content {
    flex-direction: column;
    gap: 16px;
    align-items: stretch;
  }
  
  .title-section {
    flex-direction: column;
    gap: 12px;
    align-items: flex-start;
  }
  
  .controls-section {
    justify-content: flex-start;
  }
  
  .page-title {
    font-size: 20px;
  }
  
  .messages-container {
    height: 50vh;
    min-height: 300px;
  }
  
  .control-buttons {
    flex-direction: column;
    gap: 12px;
  }
  
  .recording-time {
    min-width: 280px;
    padding: 12px 16px;
  }
  
  .duration-text {
    font-size: 14px;
  }
  
  .record-button {
    width: 100%;
    max-width: 300px;
  }
}
</style> 