"""
SenseVoice å®æ—¶è¯­éŸ³è¯†åˆ«æœåŠ¡ - ä¸»æœåŠ¡å™¨æ–‡ä»¶
"""

import argparse
import traceback
import json
import time
from typing import Optional
from urllib.parse import parse_qs

import uvicorn
import numpy as np
from fastapi import FastAPI, Request, HTTPException, WebSocket, WebSocketDisconnect
from fastapi.exceptions import RequestValidationError
from fastapi.responses import JSONResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from starlette.status import HTTP_422_UNPROCESSABLE_ENTITY
from loguru import logger
from pydantic import BaseModel

from config import setup_logging, config
from model_service import model_service_lifespan, async_vad_generate, asr_async
from audio_buffer import AudioBuffer, CircularAudioBuffer
from speaker_recognition import diarize_speaker_online_improved_async
from text_processing import format_str_v3, contains_chinese_english_number


# è®¾ç½®æ—¥å¿—
setup_logging()


class TranscriptionResponse(BaseModel):
    """è½¬å½•å“åº”æ¨¡å‹"""
    code: int
    msg: str
    data: str
    speaker_id: Optional[str] = None  # è¯´è¯äººID
    is_new_line: bool = False  # æ˜¯å¦éœ€è¦æ¢è¡Œ
    segment_type: str = "continue"  # æ®µè½ç±»å‹: "new_speaker", "pause", "continue"
    timestamp: float = 0.0  # æ—¶é—´æˆ³


# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="SenseVoiceå®æ—¶è¯­éŸ³è¯†åˆ«æœåŠ¡",
    description="åŸºäºSenseVoiceçš„å®æ—¶è¯­éŸ³è¯†åˆ«å’Œè¯´è¯äººéªŒè¯æœåŠ¡",
    version="2.0.0",
    lifespan=model_service_lifespan
)

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware, 
    allow_origins=["*"], 
    allow_credentials=True, 
    allow_methods=["*"], 
    allow_headers=["*"],
)

# æŒ‚è½½é™æ€æ–‡ä»¶ï¼ˆHTMLã€CSSã€JSç­‰ï¼‰
app.mount("/static", StaticFiles(directory="."), name="static")


@app.exception_handler(Exception)
async def custom_exception_handler(request: Request, exc: Exception):
    """å…¨å±€å¼‚å¸¸å¤„ç†å™¨"""
    logger.error("Exception occurred", exc_info=True)
    
    if isinstance(exc, HTTPException):
        status_code = exc.status_code
        message = exc.detail
    elif isinstance(exc, RequestValidationError):
        status_code = HTTP_422_UNPROCESSABLE_ENTITY
        message = "Validation error: " + str(exc.errors())
    else:
        status_code = 500
        message = "Internal server error: " + str(exc)
    
    return JSONResponse(
        status_code=status_code,
        content=TranscriptionResponse(
            code=status_code,
            msg=message,
            data=""
        ).model_dump()
    )


@app.get("/")
async def root():
    """è¿”å›å‰ç«¯ä¸»é¡µé¢"""
    return FileResponse('index.html')

@app.get("/api")
async def api_info():
    """APIä¿¡æ¯ç«¯ç‚¹"""
    return {
        "service": "SenseVoiceå®æ—¶è¯­éŸ³è¯†åˆ«æœåŠ¡",
        "version": "2.0.0",
        "status": "running",
        "features": [
            "å®æ—¶è¯­éŸ³è¯†åˆ«",
            "è¯´è¯äººéªŒè¯",
            "VADæ£€æµ‹",
            "å¤šå¹¶å‘æ”¯æŒ"
        ]
    }


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {
        "status": "healthy",
        "config": {
            "sample_rate": config.sample_rate,
            "chunk_size_ms": config.chunk_size_ms,
            "sv_threshold": config.sv_thr,
            "thread_pool_workers": config.thread_pool_max_workers
        }
    }


@app.websocket("/ws/transcribe")
async def websocket_transcribe_endpoint(websocket: WebSocket):
    """
    WebSocketè½¬å½•ç«¯ç‚¹
    
    æŸ¥è¯¢å‚æ•°:
    - sv: æ˜¯å¦å¯ç”¨è¯´è¯äººéªŒè¯ (true/false, é»˜è®¤false)
    - lang: è¯­è¨€è®¾ç½® (auto/zh/enç­‰, é»˜è®¤auto)
    
    ç¤ºä¾‹: ws://localhost:26000/ws/transcribe?sv=true&lang=auto
    """
    try:
        # è§£ææŸ¥è¯¢å‚æ•°
        query_params = parse_qs(websocket.scope['query_string'].decode())
        sv = query_params.get('sv', ['false'])[0].lower() in ['true', '1', 't', 'y', 'yes']
        lang = query_params.get('lang', ['auto'])[0].lower()
        
        await websocket.accept()

        # ä¸ºæ¯ä¸ªä¼šè¯åˆå§‹åŒ–çŠ¶æ€
        chunk_size = int(config.chunk_size_ms * config.sample_rate / 1000)
        
        # ä½¿ç”¨é«˜æ•ˆç¼“å†²åŒº
        audio_buffer = AudioBuffer(max_size=config.audio_buffer_max_size)
        vad_buffer_size = config.sample_rate * config.vad_buffer_seconds
        audio_vad = CircularAudioBuffer(max_samples=vad_buffer_size)
        
        cache_vad = {}
        cache_asr = {}
        last_vad_beg = last_vad_end = -1
        offset = 0
        
        # ä¸ºå½“å‰è¿æ¥åˆ›å»ºç‹¬ç«‹çš„å£°çº¹åº“å’Œè®¡æ•°å™¨
        speaker_gallery = {}
        speaker_counter = 0
        speaker_history = []
        current_speaker = None
        
        # æ¢è¡Œé€»è¾‘çŠ¶æ€è¿½è¸ª
        last_speaker_id = None
        last_segment_end_time = 0.0
        pause_threshold_ms = config.pause_threshold_ms  # ä»é…ç½®ä¸­è·å–åœé¡¿é˜ˆå€¼
        
        buffer = b""
        logger.info(f"WebSocket session started with chunk_size={chunk_size}, vad_buffer_size={vad_buffer_size}")
        
        # VADç¼“å†²åŒºç®¡ç†
        last_activity_time = 0  # æœ€åæ´»åŠ¨æ—¶é—´
        total_processed_samples = 0  # æ€»å¤„ç†æ ·æœ¬æ•°
        
        # éŸ³é¢‘å¤„ç†ä¸»å¾ªç¯
        while True:
            data = await websocket.receive_bytes()
            buffer += data
            if len(buffer) < 2:
                continue
                
            # å°†å­—èŠ‚æ•°æ®è½¬æ¢ä¸ºæµ®ç‚¹æ•°éŸ³é¢‘æ•°æ®
            new_audio_data = np.frombuffer(
                buffer[:len(buffer) - (len(buffer) % 2)], 
                dtype=np.int16
            ).astype(np.float32) / 32767.0
            
            audio_buffer.append(new_audio_data)
            buffer = buffer[len(buffer) - (len(buffer) % 2):]

            # å¤„ç†éŸ³é¢‘chunk
            while len(audio_buffer) >= chunk_size:
                # ä»ä¸»ç¼“å†²åŒºè·å–ä¸€ä¸ªchunk
                chunk = audio_buffer.pop_front(chunk_size)
                
                # å°†chunkæ·»åŠ åˆ°VADç¼“å†²åŒº
                audio_vad.append(chunk)
                total_processed_samples += chunk_size
                
                # æ£€æŸ¥VADç¼“å†²åŒºæ˜¯å¦æ¥è¿‘æ»¡å®¹é‡ï¼Œå¦‚æœæ˜¯åˆ™æ¸…ç†ä¸€éƒ¨åˆ†
                if len(audio_vad) > vad_buffer_size * config.vad_buffer_cleanup_threshold:
                    cleanup_samples = int(vad_buffer_size * config.vad_buffer_cleanup_ratio)
                    audio_vad.pop_front(cleanup_samples)
                    offset += cleanup_samples / config.sample_rate * 1000
                    logger.debug(f"VAD buffer cleanup: removed {cleanup_samples} samples, new offset: {offset:.1f}ms")
                
                # ä½¿ç”¨å¼‚æ­¥VADæ¨ç†
                res = await async_vad_generate(chunk, cache_vad, config.chunk_size_ms)
                
                # æ£€æŸ¥é•¿æ—¶é—´æ— è¯­éŸ³æ´»åŠ¨ï¼Œé‡ç½®offsetä»¥é¿å…ç´¯ç§¯è¯¯å·®
                silence_duration = (total_processed_samples - last_activity_time) / config.sample_rate
                if silence_duration > config.silence_reset_seconds:
                    logger.info(f"Long silence detected ({silence_duration:.1f}s), resetting VAD buffer offset")
                    # ä¿ç•™æœ€è¿‘å‡ ç§’çš„éŸ³é¢‘æ•°æ®
                    keep_samples = int(config.keep_audio_seconds * config.sample_rate)
                    if len(audio_vad) > keep_samples:
                        discard_samples = len(audio_vad) - keep_samples
                        audio_vad.pop_front(discard_samples)
                        offset += discard_samples / config.sample_rate * 1000
                    last_activity_time = total_processed_samples
                
                if len(res[0]["value"]):
                    for segment in res[0]["value"]:
                        if segment[0] > -1: 
                            last_vad_beg = segment[0]
                        if segment[1] > -1: 
                            last_vad_end = segment[1]
                        
                        if last_vad_beg > -1 and last_vad_end > -1:
                            # æ›´æ–°æœ€åæ´»åŠ¨æ—¶é—´
                            last_activity_time = total_processed_samples
                            
                            beg = int((last_vad_beg - offset) * config.sample_rate / 1000)
                            end = int((last_vad_end - offset) * config.sample_rate / 1000)
                            
                            # ç¡®ä¿ç´¢å¼•ä¸è¶…å‡ºVADç¼“å†²åŒºèŒƒå›´
                            vad_buffer_length = len(audio_vad)
                            if beg < vad_buffer_length and end > beg and beg >= 0:
                                end = min(end, vad_buffer_length)
                                segment_length = end - beg
                                
                                segment_audio = audio_vad.get_range(beg, segment_length)
                                logger.info(f"[vad segment] audio_len: {len(segment_audio)}, beg: {beg}, end: {end}")

                                speaker_id = "å‘è¨€äºº"  # é»˜è®¤ID
                                if sv and len(segment_audio) > 0:
                                    # ä½¿ç”¨æ”¹è¿›çš„å¼‚æ­¥è¯´è¯äººè¯†åˆ«ç®—æ³•
                                    try:
                                        speaker_id, speaker_gallery, speaker_counter, speaker_history, current_speaker = await diarize_speaker_online_improved_async(
                                            segment_audio, speaker_gallery, speaker_counter, config.sv_thr,
                                            speaker_history, current_speaker
                                        )
                                    except Exception as e:
                                        logger.error(f"Speaker verification error: {e}")
                                        speaker_id = "å‘è¨€äºº"
                                
                                # è¿›è¡Œå¼‚æ­¥è¯­éŸ³è¯†åˆ«
                                try:
                                    result = await asr_async(segment_audio, lang.strip(), cache_asr, True)
                                    logger.info(f"asr response: {result}")
                                    
                                    if result is not None and contains_chinese_english_number(result[0]['text']):
                                        formatted_text = format_str_v3(result[0]['text'])
                                        
                                        # è®¡ç®—å½“å‰æ—¶é—´æˆ³
                                        current_timestamp = time.time()
                                        current_segment_start_time = last_vad_beg  # VADå¼€å§‹æ—¶é—´
                                        
                                        # åˆ¤æ–­æ˜¯å¦éœ€è¦æ¢è¡Œ
                                        is_new_line = False
                                        segment_type = "continue"
                                        
                                        if config.enable_smart_line_break:
                                            # æ™ºèƒ½æ¢è¡Œæ¨¡å¼
                                            # 1. å‘è¨€äººå˜åŒ–æ£€æµ‹
                                            if last_speaker_id is not None and speaker_id != last_speaker_id:
                                                is_new_line = True
                                                segment_type = "new_speaker"
                                                logger.info(f"Speaker changed: {last_speaker_id} -> {speaker_id}")
                                            
                                            # 2. åœé¡¿æ£€æµ‹ï¼ˆåªæœ‰åœ¨åŒä¸€å‘è¨€äººæ—¶æ‰æ£€æµ‹åœé¡¿ï¼‰
                                            elif last_speaker_id == speaker_id and last_segment_end_time > 0:
                                                pause_duration = current_segment_start_time - last_segment_end_time
                                                if pause_duration > pause_threshold_ms:
                                                    is_new_line = True
                                                    segment_type = "pause"
                                                    logger.info(f"Long pause detected: {pause_duration:.1f}ms > {pause_threshold_ms}ms")
                                            
                                            # 3. é¦–æ¬¡è¯†åˆ«
                                            elif last_speaker_id is None:
                                                is_new_line = True
                                                segment_type = "new_speaker"
                                                logger.info(f"First speech segment from {speaker_id}")
                                        else:
                                            # ä¼ ç»Ÿæ¨¡å¼ï¼šæ¯æ¬¡éƒ½æ¢è¡Œ
                                            is_new_line = True
                                            segment_type = "traditional"
                                        
                                        # ç”Ÿæˆæœ€ç»ˆæ•°æ®ï¼ˆåªåŒ…å«çº¯æ–‡æœ¬ï¼Œå‘è¨€äººä¿¡æ¯é€šè¿‡å•ç‹¬å­—æ®µä¼ é€’ï¼‰
                                        final_data = formatted_text
                                        
                                        # åˆ›å»ºå“åº”
                                        response = TranscriptionResponse(
                                            code=0,
                                            msg=json.dumps(result[0], ensure_ascii=False),
                                            data=final_data,
                                            speaker_id=speaker_id,
                                            is_new_line=is_new_line,
                                            segment_type=segment_type,
                                            timestamp=current_timestamp
                                        )
                                        await websocket.send_json(response.model_dump())
                                        
                                        # æ›´æ–°çŠ¶æ€
                                        last_speaker_id = speaker_id
                                        last_segment_end_time = last_vad_end
                                        
                                except Exception as e:
                                    logger.error(f"ASR processing error: {e}")
                                
                                # æ¸…ç†å·²å¤„ç†çš„VADæ•°æ®ï¼ˆä¿ç•™ä¸€äº›é‡å ä»¥ç¡®ä¿è¿ç»­æ€§ï¼‰
                                overlap_samples = int(0.1 * config.sample_rate)  # 100msé‡å 
                                clear_length = max(0, end - overlap_samples)
                                if clear_length > 0:
                                    audio_vad.pop_front(clear_length)
                                    offset += clear_length / config.sample_rate * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
                                
                                last_vad_beg = last_vad_end = -1
                                
    except WebSocketDisconnect:
        logger.info("WebSocket disconnected")
    except Exception as e:
        logger.error(f"Unexpected error: {e}\nCall stack:\n{traceback.format_exc()}")
        await websocket.close()
    finally:
        logger.info("Cleaned up resources after WebSocket disconnect")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="è¿è¡ŒSenseVoiceå®æ—¶è¯­éŸ³è¯†åˆ«æœåŠ¡")
    parser.add_argument('--port', type=int, default=26000, help='æœåŠ¡ç«¯å£å·')
    parser.add_argument('--host', type=str, default="0.0.0.0", help='æœåŠ¡ä¸»æœºåœ°å€')
    parser.add_argument('--certfile', type=str, help='SSLè¯ä¹¦æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--keyfile', type=str, help='SSLå¯†é’¥æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--workers', type=int, default=1, help='å·¥ä½œè¿›ç¨‹æ•°')
    parser.add_argument('--log-level', type=str, default="info", 
                      choices=['debug', 'info', 'warning', 'error'],
                      help='æ—¥å¿—çº§åˆ«')
    parser.add_argument('--env', type=str, default="auto", 
                      choices=['local', 'server', 'auto'],
                      help='è¿è¡Œç¯å¢ƒ: local(æœ¬åœ°), server(æœåŠ¡å™¨), auto(è‡ªåŠ¨æ£€æµ‹)')
    
    args = parser.parse_args()
    
    # ç¯å¢ƒæ£€æµ‹å’Œé…ç½®
    if args.env == "auto":
        # è‡ªåŠ¨æ£€æµ‹ï¼šå¦‚æœæä¾›äº†SSLè¯ä¹¦ï¼Œè®¤ä¸ºæ˜¯æœåŠ¡å™¨ç¯å¢ƒ
        is_server = bool(args.certfile and args.keyfile)
    else:
        is_server = args.env == "server"
    
    # æ ¹æ®ç¯å¢ƒè°ƒæ•´é»˜è®¤é…ç½®
    if is_server:
        # æœåŠ¡å™¨ç¯å¢ƒï¼šéœ€è¦SSLè¯ä¹¦
        if not args.certfile or not args.keyfile:
            logger.warning("æœåŠ¡å™¨ç¯å¢ƒéœ€è¦SSLè¯ä¹¦ï¼Œè¯·æä¾› --certfile å’Œ --keyfile å‚æ•°")
            logger.info("ç¤ºä¾‹: python main.py --env server --port 8989 --certfile /path/to/cert.pem --keyfile /path/to/key.pem")
        protocol = "wss" if (args.certfile and args.keyfile) else "ws"
        logger.info(f"ğŸŒ æœåŠ¡å™¨æ¨¡å¼å¯åŠ¨ ({protocol})")
    else:
        # æœ¬åœ°ç¯å¢ƒï¼šä¸ä½¿ç”¨SSL
        protocol = "ws"
        logger.info("ğŸ  æœ¬åœ°æ¨¡å¼å¯åŠ¨ (ws)")
    
    logger.info(f"å¯åŠ¨SenseVoiceå®æ—¶è¯­éŸ³è¯†åˆ«æœåŠ¡...")
    logger.info(f"æœåŠ¡åœ°å€: {args.host}:{args.port}")
    logger.info(f"åè®®: {protocol}://")
    logger.info(f"é…ç½®ä¿¡æ¯: é‡‡æ ·ç‡={config.sample_rate}Hz, å—å¤§å°={config.chunk_size_ms}ms")
    logger.info(f"è¯´è¯äººéªŒè¯é˜ˆå€¼: {config.sv_thr}")
    logger.info(f"çº¿ç¨‹æ± å·¥ä½œçº¿ç¨‹æ•°: {config.thread_pool_max_workers}")
    
    # å¯åŠ¨æœåŠ¡
    try:
        run_kwargs = {
            "app": app,
            "host": args.host,
            "port": args.port,
            "log_level": args.log_level,
        }
        
        # åªæœ‰åœ¨æœåŠ¡å™¨æ¨¡å¼ä¸”æä¾›äº†è¯ä¹¦æ—¶æ‰å¯ç”¨SSL
        if is_server and args.certfile and args.keyfile:
            run_kwargs["ssl_keyfile"] = args.keyfile
            run_kwargs["ssl_certfile"] = args.certfile
            logger.info(f"SSLå·²å¯ç”¨: è¯ä¹¦={args.certfile}, å¯†é’¥={args.keyfile}")
        
        if args.workers > 1:
            run_kwargs["workers"] = args.workers
            
        uvicorn.run(**run_kwargs)
    except Exception as e:
        logger.error(f"æœåŠ¡å¯åŠ¨å¤±è´¥: {e}")
 